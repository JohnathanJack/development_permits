{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.shapeyourcity.ca/development'\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver-win64\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_urls(webpage,path):\n",
    "    \"\"\"\n",
    "    Scrapes all the URLs of the development permits within the webpage\n",
    "\n",
    "    Parameters:\n",
    "        webpage (str): the url of the webpage\n",
    "        path (str): the location of the user's chromedriver\n",
    "\n",
    "    Returns:\n",
    "        A list of strings which contains all of the development permits url \n",
    "    \"\"\"\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(service = Service(path), options=chrome_options)\n",
    "    driver.get(webpage)\n",
    "    # The element is located within an iframe, required to locate the iframe and switch frames\n",
    "    iframe = driver.find_element(By.TAG_NAME, 'iframe')\n",
    "    url_list = []\n",
    "    driver.switch_to.frame(iframe)\n",
    "    page_num = WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \".chakra-button.ehq-paginationButton.css-i1louw\")))\n",
    "    last_page_num = int([item.text for item in page_num][-2])\n",
    "    # Scrape all of the urls on each page\n",
    "    for num in range(last_page_num+1):\n",
    "        # Ensures that all the CSS elements are loaded before scraping\n",
    "        urls = WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, '.chakra-link.ehq-projectCoverImg.css-1eh7kaa')))\n",
    "        for url in urls:\n",
    "            url_list.append(url.get_attribute('href'))\n",
    "        # After scraping all of the elements, click to the next page if not on the final page\n",
    "        if num < last_page_num+1:\n",
    "            click = driver.find_element(By.CSS_SELECTOR, \".chakra-button.ehq-paginationButton.ehq-paginationNextButton.css-i1louw\")\n",
    "            click.click()\n",
    "        else:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "    driver.switch_to.default_content()\n",
    "    driver.quit()\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_permit_urls = get_list_of_urls(url, PATH)\n",
    "# save the urls to a pickle file that can be opened at any time without re-running the code. \n",
    "with open('permit_urls', 'wb') as f:\n",
    "    pickle.dump(all_permit_urls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved pickle with all the URLs.\n",
    "all_permit_urls_saved = pd.read_pickle('permit_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permit_ids(list_of_urls, path):\n",
    "    \"\"\"\n",
    "    Scrapes each webpage to obtain the development permit id\n",
    "\n",
    "    Parameters:\n",
    "        list_of_urls (list of str): the urls of the webpage derived from the get_list_of_urls function\n",
    "        path (str): the location of the user's chromedriver\n",
    "\n",
    "    Returns:\n",
    "        A list of the development permit ids \n",
    "    \"\"\"\n",
    "    \n",
    "    header_list = []\n",
    "    regex = r'\\((.*?)\\)'\n",
    "    for url in list_of_urls:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless=new\")\n",
    "        driver = webdriver.Chrome(service = Service(path), options=chrome_options)\n",
    "        driver.get(url)\n",
    "        header_list.append(driver.find_element(By.TAG_NAME, 'h1').text)\n",
    "        driver.quit()\n",
    "        time.sleep(3)\n",
    "    permit_list = [re.search(regex, permit)[1] for permit in header_list]\n",
    "    return permit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(list_of_urls, path):\n",
    "    \"\"\"\n",
    "    Scrapes each webpage to obtain the description of each development permit application\n",
    "\n",
    "    Parameters:\n",
    "        list_of_urls (list of str): the urls of the webpage derived from the get_list_of_urls function\n",
    "        path (str): the location of the user's chromedriver\n",
    "\n",
    "    Returns:\n",
    "        A list of the description of each development permit application \n",
    "    \"\"\"\n",
    "\n",
    "    regex = r'(.*?)Under the'\n",
    "    description_list = []\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    for url in list_of_urls:\n",
    "        driver = webdriver.Chrome(service = Service(path), options=chrome_options)\n",
    "        driver.get(url)\n",
    "        text = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CLASS_NAME, 'truncated-description'))).text\n",
    "        end_point = re.search(regex, text).span()[0]\n",
    "        description = text[:end_point]\n",
    "        description_list.append(description)\n",
    "        driver.quit()\n",
    "        time.sleep(3)\n",
    "    return description_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_applicant(list_of_description):\n",
    "    \"\"\"\n",
    "    Utilizes regex to obtain the applicants name from the list of description\n",
    "\n",
    "    Parameters:\n",
    "        list_of_description (list of str): the description of the webpage derived from the get_description \n",
    "\n",
    "    Returns:\n",
    "        A list of the applicant names \n",
    "    \"\"\"\n",
    "    \n",
    "    regex = r'^.*?(?=\\s+has applied)'\n",
    "    list_of_applicant = []\n",
    "    for applicant in list_of_description:\n",
    "        try:\n",
    "            applicant_name = applicant[:re.search(regex, applicant).span()[1]]\n",
    "        except:\n",
    "            applicant_name = 'Unknown'\n",
    "        list_of_applicant.append(applicant_name)\n",
    "    return list_of_applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_status(list_of_urls, path):\n",
    "    \"\"\"\n",
    "    Scrapes each webpage to obtain the Director of Planning decision\n",
    "\n",
    "    Parameters:\n",
    "        list_of_urls (list of str): the urls of the webpage derived from the get_list_of_urls function\n",
    "        path (str): the location of the user's chromedriver\n",
    "\n",
    "    Returns:\n",
    "        A list of application status\n",
    "    \"\"\"  \n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    list_status = []\n",
    "    for url in list_of_urls:\n",
    "        driver = webdriver.Chrome(service = Service(path), options = chrome_options)\n",
    "        driver.get(url)\n",
    "        text_info = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.TAG_NAME,'strong'))).text.split()\n",
    "        if 'Director' in text_info:\n",
    "            if 'approved' in text_info:\n",
    "                list_status.append('Approved')\n",
    "            elif 'cancelled' in text_info:\n",
    "                list_status.append('Cancelled')\n",
    "            elif 'withdrawn' in text_info:\n",
    "                list_status.append('Withdrawn')\n",
    "            else:\n",
    "                list_status.append('Rejected')\n",
    "        else:\n",
    "            list_status.append('In progress')\n",
    "        driver.quit()\n",
    "        time.sleep(3)\n",
    "    return list_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [385]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m permit_id \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermit_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mget_permit_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_permit_urls_saved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[0;32m      2\u001b[0m description \u001b[38;5;241m=\u001b[39m get_description(all_permit_urls_saved, PATH)\n\u001b[0;32m      3\u001b[0m list_of_applicants \u001b[38;5;241m=\u001b[39m get_list_of_applicant(description)\n",
      "Input \u001b[1;32mIn [381]\u001b[0m, in \u001b[0;36mget_permit_ids\u001b[1;34m(list_of_urls, path)\u001b[0m\n\u001b[0;32m     21\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     22\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m permit_list \u001b[38;5;241m=\u001b[39m [re\u001b[38;5;241m.\u001b[39msearch(regex, permit)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m permit \u001b[38;5;129;01min\u001b[39;00m header_list]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m permit_list\n",
      "Input \u001b[1;32mIn [381]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     22\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m permit_list \u001b[38;5;241m=\u001b[39m [\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m permit \u001b[38;5;129;01min\u001b[39;00m header_list]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m permit_list\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "permit_id = {'permit_id': get_permit_ids(all_permit_urls_saved, PATH)}\n",
    "description = get_description(all_permit_urls_saved, PATH)\n",
    "list_of_applicants = get_list_of_applicant(description)\n",
    "applicant_status = application_status(all_permit_urls_saved, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(permit_id)\n",
    "df['description'] = description\n",
    "df['applicant'] = list_of_applicants\n",
    "df['applicant_status'] = applicant_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_status(driver):\n",
    "    \"\"\"\n",
    "    Scrape webpage to obtain the Director of Planning decision\n",
    "\n",
    "    Parameters:\n",
    "        driver: the driver that opened the webpage\n",
    "\n",
    "    Returns:\n",
    "        The application status\n",
    "    \"\"\"  \n",
    "\n",
    "    try:\n",
    "        text_info = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.TAG_NAME,'strong'))).text.split()\n",
    "        if 'Director' in text_info:\n",
    "            if 'approved' in text_info:\n",
    "                return 'Approved'\n",
    "            elif 'cancelled' in text_info:\n",
    "                return 'Cancelled'\n",
    "            elif 'withdrawn' in text_info:\n",
    "                return 'Withdrawn'\n",
    "            else:\n",
    "                'Rejected'\n",
    "        else:\n",
    "            return 'In progress'\n",
    "    except:\n",
    "        return 'In progress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permit_status(driver, regex):\n",
    "    \"\"\"\n",
    "    Scrapes webpage to obtain the development permit id\n",
    "\n",
    "    Parameters:\n",
    "        driver: the driver that opened the webpage\n",
    "        regex: the regular expression required to isolate the permit id\n",
    "\n",
    "    Returns:\n",
    "        The development permit id \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        head_text = driver.find_element(By.TAG_NAME, 'h1').text\n",
    "        permit_id = re.search(regex, head_text)[1] \n",
    "    except:\n",
    "        permit_id = 'Unknown'\n",
    "    return permit_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_description(driver):\n",
    "    \"\"\"\n",
    "    Scrapes each webpage to obtain the description of each development permit application\n",
    "\n",
    "    Parameters:\n",
    "        driver: the driver that opened the webpage\n",
    "\n",
    "    Returns:\n",
    "        The description of the development permit application \n",
    "    \"\"\"\n",
    "\n",
    "    text = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CLASS_NAME, 'truncated-description'))).text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info(list_of_urls, path):\n",
    "    \"\"\"\n",
    "    Scrapes each webpage in the list of urls\n",
    "\n",
    "    Parameters:\n",
    "        list_of_urls (list of str): all the urls to be scraped\n",
    "        path (str): the location of the user's chromedriver\n",
    "\n",
    "    Returns:\n",
    "        A tuple where the 0th element is the list status, the 1st element is the description list, and the 2nd element is the permit list\n",
    "    \"\"\"\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    list_status = []\n",
    "    description_list = []\n",
    "    permit_list = []\n",
    "    error_list = []\n",
    "    regex_permit = r'\\((.*?)\\)'\n",
    "    for url in list_of_urls:\n",
    "        driver = webdriver.Chrome(service = Service(path), options = chrome_options)\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            list_status.append(application_status(driver))\n",
    "            permit_list.append(permit_status(driver, regex_permit))\n",
    "            description_list.append(scrape_description(driver))\n",
    "            driver.quit()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            error_list.append(url)\n",
    "            driver.quit()\n",
    "            time.sleep(3)\n",
    "    return list_status, description_list, permit_list, error_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_permit_urls_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_information_100 = scrape_info(all_permit_urls_saved[100:200], PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_information_100[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.shapeyourcity.ca/3596-w-28-ave',\n",
       " 'https://www.shapeyourcity.ca/false-creek-north-non-market-housing']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_information_200 = scrape_info(all_permit_urls_saved[200:300], PATH)\n",
    "scraped_information_200[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_information_300 = scrape_info(all_permit_urls_saved[300:400], PATH)\n",
    "scraped_information_300[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_information_400 = scrape_info(all_permit_urls_saved[400:500], PATH)\n",
    "scraped_information_400[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_information_500 = scrape_info(all_permit_urls_saved[500:], PATH)\n",
    "scraped_information_500[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_information = scrape_info(all_permit_urls_saved[:100], PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
